---
title: Installation & Configuration
description: Install AUTOUI and configure it with a minimal working example. Learn about AutoUIConfig structure and required fields.
keywords: ["installation", "configuration", "autouiconfig", "setup", "quickstart"]
---

This guide covers installing AUTOUI and creating your first working configuration.

## Installation

Install AUTOUI using your preferred package manager:

<Tabs defaultValue="npm" className="pt-5 pb-1">
  <TabsList>
    <TabsTrigger value="npm">npm</TabsTrigger>
    <TabsTrigger value="pnpm">pnpm</TabsTrigger>
    <TabsTrigger value="yarn">yarn</TabsTrigger>
  </TabsList>
  <TabsContent value="npm">
```bash
npm install @autoai-ui/autoui
```
  </TabsContent>
  <TabsContent value="pnpm">
```bash
pnpm add @autoai-ui/autoui
```
  </TabsContent>
  <TabsContent value="yarn">
```bash
yarn add @autoai-ui/autoui
```
  </TabsContent>
</Tabs>

## Quickstart

Here's a minimal working example:

```tsx
"use client"
import { ModalChat, AutoUIConfig } from "@autoai-ui/autoui"
import dynamic from "next/dynamic"

// Important: ModalChat must be dynamically imported with SSR disabled
const ModalChat = dynamic(
  () => import("@autoai-ui/autoui").then(m => m.ModalChat),
  { ssr: false }
)

export default function MyApp() {
  const config: AutoUIConfig = {
    appId: 'my-app',
    
    metadata: {
      appName: 'My App',
      appVersion: '1.0.0',
      author: 'Your Name',
      createdAt: new Date().toISOString(),
      description: 'A simple app with an AI assistant.',
      tags: ['demo'],
    },
    
    llm: {
      proxyUrl: 'http://localhost:3001', // Your proxy server URL
      sharedSecret: 'your-client-key',    // Generated by proxy server
      appDescriptionPrompt: 'A simple application.',
      temperature: 0.2,
      maxTokens: 2048,
    },
    
    runtime: {
      validateLLMOutput: true,
      storeChatToLocalStorage: true,
      localStorageKey: 'autoui_chat',
      enableDebugLogs: false,
      maxSteps: 20,
      errorHandling: {
        showToUser: true,
        retryOnFail: false,
      },
    },
  }

  return (
    <div>
      <h1>My App</h1>
      <ModalChat config={config} />
    </div>
  )
}
```

<Note title="SSR Requirement" type="danger">
ModalChat must be dynamically imported with `ssr: false` in Next.js or similar SSR frameworks. This prevents hydration mismatches.
</Note>

<Note title="Optional: Functions and Components" type="success">
The minimal example above doesn't include `functions` or `components`, but you can add them to enable the assistant to interact with your app and render custom UI. See the [Complete Config Example](#complete-config-example) below for a full example with both functions and components.
</Note>

## Configuration Guide

Your `AutoUIConfig` is the **contract** between your app and the AI assistant. It defines what the assistant knows about your app and what actions it can take.

### Mental Model

Think of your config as a **specification document**:
- **Metadata** describes your app to the LLM
- **Functions** are actions the assistant can trigger
- **Components** are UI elements the assistant can render
- **Runtime** controls execution behavior

The LLM reads your config and generates plans (structured JSON) that the runtime executes.

## Complete Config Structure

The `AutoUIConfig` object contains the following properties:

```tsx
interface AutoUIConfig {
  appId: string                    // Required: Unique app identifier
  metadata: Metadata               // Required: App metadata
  llm: LLMConfig                   // Required: LLM provider settings
  runtime: RuntimeConfig           // Required: Runtime execution settings
  functions?: FunctionsConfig      // Optional: Registered functions
  components?: ComponentsConfig    // Optional: Registered React components
}
```

<Note title="Both Functions and Components Are Optional" type="success">
You can include `functions`, `components`, both, or neither—depending on your needs. Functions enable the assistant to interact with your app's state and logic, while components enable generative UI. They work great together! See the [Complete Config Example](#complete-config-example) below for an example with both.
</Note>

## Config Properties

### `appId` (required)

**Type:** `string`

A unique identifier for your application. Used for logging, analytics, and localStorage keys.

```tsx
appId: 'tasks-demo'
```

**Guidelines:**
- Use lowercase letters, numbers, and hyphens
- Keep it short and descriptive
- Should be unique across your deployments
- Examples: `'my-app'`, `'tasks-demo'`, `'ecommerce-store'`

### `metadata` (required)

**Type:** `Metadata`

App metadata that helps the LLM understand your application's purpose and context. This is sent to the LLM on every request.

```tsx
metadata: {
  appName: 'AutoUI Task Manager',        // Display name for your app
  appVersion: '0.1.0',                   // Version string (semantic versioning recommended)
  author: 'AutoUI Dev Team',             // Author or team name
  createdAt: new Date().toISOString(),   // ISO 8601 timestamp (e.g., '2024-01-15T10:30:00.000Z')
  description: 'Task management demo app with tasks list, filters, stats, and task editor modal. Always respond politely. If user intent is unclear, suggest UI actions. After opening UI outside the chat, suggest closing the chat widget.', // Detailed description for LLM
  tags: ['demo', 'tasks', 'productivity'], // Array of tags for categorization
}
```

**Property Details:**

| Property | Type | Required | Description |
|----------|------|----------|-------------|
| `appName` | `string` | Yes | Display name of your application. Shown in logs and debugging. |
| `appVersion` | `string` | Yes | Version string (e.g., "1.0.0", "0.2.5"). Used for version tracking. |
| `author` | `string` | Yes | Author or team name. Useful for attribution and debugging. |
| `createdAt` | `string` | Yes | ISO 8601 timestamp. Use `new Date().toISOString()` to generate. |
| `description` | `string` | Yes | **Critical field.** Detailed description that tells the LLM what your app does. Be specific about features, workflows, user intents, and behavioral instructions. |
| `tags` | `string[]` | Yes | Array of tags for categorization and filtering. Examples: `['demo', 'tasks', 'productivity']` |

**Important Notes:**
- The `description` field is **crucial**—it's the primary way the LLM understands your app's purpose and capabilities. Be detailed and specific.
- Include behavioral instructions in the description (e.g., "Always respond politely", "If user intent is unclear, suggest UI actions").
- Tags help with organization but don't affect LLM behavior directly.

### `llm` (required)

**Type:** `LLMConfig`

LLM provider configuration. This controls how AUTOUI communicates with the LLM through your proxy server.

```tsx
llm: {
  proxyUrl: 'http://localhost:3001',           // Proxy server URL
  sharedSecret: 'your-client-key-here',        // Client key from proxy server
  appDescriptionPrompt: 'A task management app with task list, filters, status changes, statistics, and a task editor form.', // Short prompt for LLM
  temperature: 0.2,                            // Optional: 0.0-2.0, lower = more deterministic
  maxTokens: 2048,                             // Optional: Max response length in tokens
}
```

**Property Details:**

| Property | Type | Required | Default | Description |
|----------|------|----------|---------|-------------|
| `proxyUrl` | `string` | Yes | - | URL of your proxy server (e.g., `'http://localhost:3001'` or `'https://api.yourdomain.com'`). Must include protocol (http/https). |
| `sharedSecret` | `string` | Yes | - | Client key (shared secret) generated by your proxy server. This is different from your OpenRouter API key and can be safely included in frontend code. |
| `appDescriptionPrompt` | `string` | Yes | - | Concise description of your app's capabilities. Shorter than `metadata.description`, focused on what the app can do. |
| `temperature` | `number` | No | `0.2` | Controls randomness in LLM responses (0.0-2.0). Lower values = more deterministic, higher = more creative. Recommended: 0.1-0.3 for structured outputs. |
| `maxTokens` | `number` | No | `2048` | Maximum number of tokens in the LLM response. Larger values allow longer plans but cost more. Typical range: 1024-4096. |

**Security Note:**
- `sharedSecret` is safe to include in frontend code—it's different from your OpenRouter API key
- Never put your OpenRouter API key in this config
- See [Backend Proxy](/docs/backend-proxy) guide for proxy setup

### `runtime` (required)

**Type:** `RuntimeConfig`

Controls how the AUTOUI runtime executes plans and handles errors.

```tsx
runtime: {
  validateLLMOutput: true,              // Validate plan JSON structure
  storeChatToLocalStorage: true,        // Persist chat history to browser storage
  localStorageKey: 'autoui_tasks_demo', // Optional: Key for localStorage
  enableDebugLogs: true,                // Log execution details to browser console
  maxSteps: 20,                         // Maximum plan steps per execution
  errorHandling: {
    showToUser: true,                   // Display errors in chat UI
    retryOnFail: false,                 // Auto-retry failed function calls
  },
}
```

**Property Details:**

| Property | Type | Required | Default | Description |
|----------|------|----------|---------|-------------|
| `validateLLMOutput` | `boolean` | Yes | - | Validates that LLM responses are properly structured plan JSON. Recommended: `true` for production. Set to `false` only for debugging. |
| `storeChatToLocalStorage` | `boolean` | Yes | - | Persists conversation history to browser localStorage. Enables chat to survive page reloads. |
| `localStorageKey` | `string` | No | `'autoui_chat'` | Key used for storing chat history in localStorage. Use different keys for different apps/instances. |
| `enableDebugLogs` | `boolean` | Yes | - | Logs detailed execution information to browser console. Useful during development, disable in production. |
| `maxSteps` | `number` | Yes | - | Maximum number of steps allowed in a single plan execution. Prevents infinite loops. Typical values: 10-50. |
| `errorHandling.showToUser` | `boolean` | Yes | - | Whether to display error messages in the chat UI. `true` = show errors to users, `false` = only log to console. |
| `errorHandling.retryOnFail` | `boolean` | Yes | - | Whether to automatically retry failed function calls once. Only enable for idempotent operations. |

**Best Practices:**
- Set `validateLLMOutput: true` in production
- Use `enableDebugLogs: false` in production to reduce console noise
- Set `maxSteps` based on your app's complexity (simple apps: 10-20, complex: 30-50)
- Only enable `retryOnFail` for idempotent functions

### `functions` (optional)

**Type:** `Record<string, FunctionConfig>`

Register JavaScript functions that the AI assistant can call. Functions enable the assistant to interact with your application state, trigger side effects, and return data.

**Structure:**

```tsx
functions: {
  functionName: {
    prompt: string,                              // Description of what the function does
    params?: Record<string, string>,             // Parameter descriptions
    callFunc: (params: any) => any,              // The actual function to execute
    returns?: string,                            // Description of return value
  },
  // ... more functions
}
```

**Complete Example:**

```tsx
functions: {
  // Example 1: Function with parameters
  createTask: {
    prompt: 'Create a new Task object from a TaskDraft by adding id and created_at timestamp. Use this when the user asks to create, add, or make a new task.',
    params: {
      draft: 'TaskDraft — { title: string, description?: string, status: "todo" | "in-progress" | "done", priority: "low" | "medium" | "high", due_date?: string }',
    },
    callFunc: ({ draft }: { draft: TaskDraft }) => {
      const task = {
        ...draft,
        id: `task-${Date.now()}`,
        created_at: new Date().toISOString(),
      }
      tasks.push(task) // Assume tasks is in scope
      return task
    },
    returns: 'Task — full task object with generated id and created_at fields.',
  },

  // Example 2: Function without parameters
  getCurrentTasks: {
    prompt: 'Return the current list of tasks from application state. Use this when the user asks to see, list, or get all tasks.',
    callFunc: () => tasks, // Assume tasks is in scope
    returns: 'Task[] — array of all tasks',
  },

  // Example 3: Function that triggers side effects
  openTaskForm: {
    prompt: 'Open the task creation form in the main app UI. After opening, tell the user they can close the chat and continue in the form.',
    callFunc: () => {
      setShowForm(true) // Assume setShowForm is in scope
    },
  },

  // Example 4: Async function
  fetchUserData: {
    prompt: 'Fetch user data from the API.',
    params: {
      userId: 'string — unique user identifier',
    },
    callFunc: async ({ userId }: { userId: string }) => {
      const response = await fetch(`/api/users/${userId}`)
      return await response.json()
    },
    returns: 'User — user object with id, name, email',
  },

  // Example 5: Function with computed results
  summarizeTasks: {
    prompt: 'Compute task statistics: total count and counts by status and priority.',
    params: {
      tasks: 'Task[] — current list of tasks',
    },
    callFunc: ({ tasks }: { tasks: Task[] }) => {
      const total = tasks.length
      const byStatus: Record<string, number> = {}
      const byPriority: Record<string, number> = {}

      for (const t of tasks) {
        byStatus[t.status] = (byStatus[t.status] ?? 0) + 1
        byPriority[t.priority] = (byPriority[t.priority] ?? 0) + 1
      }

      return { total, byStatus, byPriority }
    },
    returns: '{ total: number, byStatus: Record<string, number>, byPriority: Record<string, number> }',
  },
}
```

**Function Property Details:**

| Property | Type | Required | Description |
|----------|------|----------|-------------|
| `prompt` | `string` | Yes | Natural language description of what the function does and when to use it. Be specific—the LLM uses this to decide whether to call the function. |
| `params` | `Record<string, string>` | No | Descriptions of function parameters. Format: `'paramName: Type — description'`. Helps LLM understand what parameters to pass. |
| `callFunc` | `Function` | Yes | The actual JavaScript function to execute. Receives parameters as an object. Can be async. Can access variables in closure (React state, etc.). |
| `returns` | `string` | No | Description of what the function returns. Format: `'Type — description'`. Helps LLM understand function output. |

**Important Notes:**
- Functions have access to variables in their closure (React state, component props, etc.)
- Functions can be async—just return a Promise
- Functions can trigger side effects (API calls, state updates, navigation, etc.)
- The `prompt` field is critical—write clear, specific descriptions
- See [Functions](/docs/functions) for detailed documentation and best practices

### `components` (optional)

**Type:** `Record<string, ComponentConfig>`

Register React components that the AI assistant can render dynamically. This enables **generative UI**—the assistant can compose new interfaces on the fly.

**Structure:**

```tsx
components: {
  ComponentName: {
    prompt: string,                              // Description of what the component displays
    props?: Record<string, string>,              // Optional: Props descriptions (helps LLM understand structure)
    defaults?: Record<string, any>,              // Default/example props (can use live data from closure)
    callComponent: Component | ((props: any) => ReactElement), // Component reference or function
    category?: string,                           // Optional category for organization
    exampleUsage?: string,                       // Optional: Example usage string (e.g., '<Component prop={value} />')
  },
  // ... more components
}
```

**Complete Example:**

```tsx
components: {
  // Example 1: Simple display component
  CartSummary: {
    prompt: 'Shows cart items with quantities and total price. Use this when the user asks to see their cart, view items, or check total.',
    defaults: {
      items: [
        { id: '1', name: 'Beige Coat', price: 89.99, quantity: 2 },
        { id: '2', name: 'Denim Jacket', price: 69.99, quantity: 1 },
      ],
    },
    callComponent: (props) => <CartSummary {...props} />,
    category: 'checkout',
  },

  // Example 2: Component with required props
  ProductCard: {
    prompt: 'Displays a single product with image, name, price, description, and add-to-cart button. Use this when showing a single product.',
    defaults: {
      id: '1',
      name: 'Product Name',
      price: 29.99,
      image: 'https://example.com/product.jpg',
      description: 'Product description here',
    },
    callComponent: (props) => <ProductCard {...props} />,
    category: 'products',
  },

  // Example 3: Layout component
  ProductGrid: {
    prompt: 'Displays a grid of product cards. Use this when showing multiple products in a grid layout.',
    defaults: {
      products: [
        { id: '1', name: 'Product 1', price: 29.99 },
        { id: '2', name: 'Product 2', price: 39.99 },
      ],
    },
    callComponent: (props) => <ProductGrid {...props} />,
    category: 'products',
  },

  // Example 4: Form component
  TaskForm: {
    prompt: 'Displays a form for creating or editing a task. Includes fields for title, description, status, priority, and due date.',
    defaults: {
      title: '',
      description: '',
      status: 'todo',
      priority: 'medium',
      dueDate: null,
    },
    callComponent: (props) => <TaskForm {...props} />,
    category: 'forms',
  },
}
```

**Component Property Details:**

| Property | Type | Required | Description |
|----------|------|----------|-------------|
| `prompt` | `string` | Yes | Natural language description of what the component displays and when to use it. The LLM uses this to decide whether to render the component. |
| `props` | `Record<string, string>` | No | Descriptions of component props. Format: `'propName: Type — description'`. Helps LLM understand prop structure, especially useful when `defaults` uses live data. |
| `defaults` | `Record<string, any>` | No | Default/example props that show the LLM what props the component expects. Can use live data from closure (e.g., `tasks` from component state). Should match your actual data structure. |
| `callComponent` | `Component \| Function` | Yes | Direct reference to your React component, or a function that returns it. You can pass the component directly: `callComponent: MyComponent` or wrap it: `callComponent: (props) => <MyComponent {...props} />`. |
| `category` | `string` | No | Optional category for organizing related components. Examples: `'products'`, `'checkout'`, `'forms'`, `'layout'`, `'tasks'`. |
| `exampleUsage` | `string` | No | Optional example of how to use the component. Format: `'<ComponentName prop={value} />'`. Helps LLM understand component usage patterns. |

**Important Notes:**
- Components are rendered inside the ModalChat context
- Props are generated by the LLM based on `defaults` and `prompt`
- Provide realistic `defaults` that match your actual data structure
- Components can be combined by the LLM to create complex UIs
- See [Components](/docs/components) for detailed documentation and examples

<Note title="Functions and Components Work Together" type="success">
You can combine functions and components. For example, a function can fetch data, and a component can display it. The LLM can orchestrate both to create complete workflows.
</Note>

## Complete Config Example

Here's a **real-world example** from a task management application. This shows the complete structure with all sections, including functions and components, organized with clear section comments.

```tsx
import { ModalChat } from '@autoai-ui/autoui'
import { useCallback } from 'react'
import type { AutoUIConfig } from '@autoai-ui/autoui'
import type { Task, TaskDraft } from './types/tasks'
import TaskItem from './components/tasks/TaskItem'
import TaskStats from './components/tasks/TaskStats'
import TasksList from './componentsForChat.tsx/TasksList'
import PointerHintButton from './componentsForChat.tsx/PointerHintButton'
import { useTasksContext } from './hooks/useAppFunctions'

const TasksApp = () => {
  const { tasks, setShowForm } = useTasksContext()

  // Helper functions that are used in the config
  const createTaskFromDraft = useCallback((draft: TaskDraft): Task => {
    return {
      ...draft,
      id: Date.now().toString(),
      created_at: new Date().toISOString(),
    }
  }, [])

  const updateTaskWithDraft = useCallback((task: Task, patch: TaskDraft): Task => {
    return {
      ...task,
      ...patch,
    }
  }, [])

  // Get proxy configuration from environment variables
  const proxyUrl = import.meta.env.VITE_BASE_URL
  const sharedSecret = import.meta.env.VITE_AUTOUI_SHARED_SECRET

  const TasksAppConfig: AutoUIConfig = {
    /* =========================
     *   APP ID (IMPORTANT)
     * ========================= */
    appId: 'tasks-demo',

    /* =========================
     *   METADATA
     * ========================= */
    metadata: {
      appName: 'AutoUI Task Manager',
      appVersion: '0.1.0',
      author: 'AutoUI Dev Team',
      createdAt: new Date().toISOString(),
      description:
        'Task management demo app with tasks list, filters, stats, and task editor modal. Always respond politely. If user intent is unclear, suggest UI actions. After opening UI outside the chat, suggest closing the chat widget.',
      tags: ['demo', 'tasks', 'productivity', 'react', 'autoui'],
    },

    /* =========================
     *   LLM (PROXY-FIRST)
     * ========================= */
    llm: {
      proxyUrl,
      sharedSecret,

      /**
       * High-level context for the assistant
       * This is sent to the LLM to help it understand your app's capabilities
       */
      appDescriptionPrompt:
        'A task management app with task list, filters, status changes, statistics, and a task editor form.',

      /**
       * Soft hints (proxy may override)
       * These are suggestions to the LLM provider
       */
      temperature: 0.2,
      maxTokens: 2048,
    },

    /* =========================
     *   RUNTIME
     * ========================= */
    runtime: {
      validateLLMOutput: true,
      storeChatToLocalStorage: true,
      localStorageKey: 'autoui_tasks_demo_chat',
      enableDebugLogs: true,
      maxSteps: 20,
      errorHandling: {
        showToUser: true,
        retryOnFail: false,
      },
    },

    /* =========================
     *   FUNCTIONS
     * ========================= */
    functions: {
      createTask: {
        prompt: 'Create a new Task object from a TaskDraft by adding id and created_at timestamp.',
        params: {
          draft: 'TaskDraft — { title, description?, status, priority, due_date? }',
        },
        callFunc: ({ draft }: { draft: TaskDraft }) => createTaskFromDraft(draft),
        returns: 'Task — full task with generated id and created_at fields.',
      },

      updateTask: {
        prompt: 'Update an existing Task using a TaskDraft patch, preserving id and created_at.',
        params: {
          task: 'Task — existing task',
          patch: 'TaskDraft — fields to update',
        },
        callFunc: ({ task, patch }: { task: Task; patch: TaskDraft }) => updateTaskWithDraft(task, patch),
        returns: 'Task — updated task object.',
      },

      summarizeTasks: {
        prompt: 'Compute task statistics: total count and counts by status and priority.',
        params: {
          tasks: 'Task[] — current list of tasks',
        },
        callFunc: ({ tasks }: { tasks: Task[] }) => {
          const total = tasks.length
          const byStatus: Record<string, number> = {}
          const byPriority: Record<string, number> = {}

          for (const t of tasks) {
            byStatus[t.status] = (byStatus[t.status] ?? 0) + 1
            byPriority[t.priority] = (byPriority[t.priority] ?? 0) + 1
          }

          return { total, byStatus, byPriority }
        },
        returns: '{ total: number, byStatus: Record<string, number>, byPriority: Record<string, number> }',
      },

      openTaskForm: {
        prompt:
          'Open the task creation form in the main app UI. After opening, tell the user they can close the chat and continue in the form.',
        callFunc: () => {
          setShowForm(true)
        },
      },

      fetchCurrentTasksState: {
        prompt: 'Return the current list of tasks from application state.',
        callFunc: () => tasks,
        // canShareDataWithLLM: true, // Optional: Explicitly allow sharing data with LLM
      },

      showHowManyTasks: {
        prompt: 'Return the number of tasks in the current task list.',
        callFunc: () => tasks.length,
      },
    },

    /* =========================
     *   COMPONENTS
     * ========================= */
    components: {
      TasksList: {
        prompt: 'Full tasks page with list, stats, filters and editor modal.',
        props: {
          tasks: 'Task[] — current task list from application state.',
        },
        defaults: {
          tasks,
        },
        callComponent: TasksList,
        category: 'layout',
        exampleUsage: '<TasksList tasks={tasks} />',
      },

      TaskItem: {
        prompt: 'Single task card with title, description, status, priority and actions.',
        props: {
          task: 'Task — task data',
        },
        defaults: {
          task: {
            id: 'example-id',
            title: 'Example Task',
            description: 'This is an example task.',
            status: 'todo',
            priority: 'medium',
            created_at: new Date().toISOString(),
          } as Task,
        },
        callComponent: TaskItem,
        category: 'tasks',
      },

      TaskStats: {
        prompt: 'Statistics bar showing counts of tasks by status and priority.',
        props: {
          tasks: 'Task[] — list of tasks',
        },
        callComponent: TaskStats,
        category: 'stats',
      },

      PointerHintButton: {
        prompt: 'Button that highlights a specific UI element using a guided pointer.',
        props: {
          target: 'string — data-guide-id of the UI element to highlight.',
        },
        callComponent: PointerHintButton,
        category: 'guide',
      },
    },
  }

  return (
    <main>
      <Tasks />
      <ModalChat config={TasksAppConfig} />
    </main>
  )
}

export default TasksApp
```

### Example Breakdown

This example demonstrates several important patterns:

**1. Section Organization**
- Uses comment blocks (`/* ========================= */`) to clearly separate config sections
- Makes the config easy to read and navigate
- Each section has a clear purpose

**2. Helper Functions**
- `createTaskFromDraft` and `updateTaskWithDraft` are defined outside the config
- These can be reused elsewhere in your app
- Keeps the config clean and maintainable

**3. Environment Variables**
- Uses `import.meta.env` (Vite) or `process.env` (Next.js) for sensitive values
- Never hardcodes proxy URLs or secrets in source code
- Supports different configurations for development/production

**4. Function Examples**
- `createTask`: Creates new tasks with auto-generated ID and timestamp
- `updateTask`: Updates existing tasks while preserving immutable fields
- `summarizeTasks`: Computes statistics from task data
- `openTaskForm`: Triggers UI state changes (opens a form)
- `fetchCurrentTasksState`: Returns current state (can access closure variables)
- `showHowManyTasks`: Simple read-only function that returns a number

**5. Component Examples**
- `TasksList`: Layout component that displays the full tasks page
- `TaskItem`: Individual task card component
- `TaskStats`: Statistics display component
- `PointerHintButton`: Interactive guide component

**6. Component Properties**
- `props`: Describes what props the component expects (helps LLM understand structure)
- `defaults`: Provides example/default values for props (can use live data from closure)
- `callComponent`: Direct reference to the component (not an arrow function wrapper)
- `category`: Organizes components by purpose
- `exampleUsage`: Shows how the component is typically used (optional, helpful for LLM)

**7. Advanced Features**
- `canShareDataWithLLM`: Commented out example showing optional property for data sharing control
- Direct component references instead of arrow functions when the component signature matches

<Note title="Key Patterns" type="success">
- **Functions have closure access**: `fetchCurrentTasksState` and `showHowManyTasks` can directly access `tasks` from the component scope
- **Components can use live data**: `TasksList` uses `tasks` from closure in its `defaults`
- **Direct component references**: You can pass components directly (`callComponent: TasksList`) instead of wrapping them
- **Props documentation**: The `props` field helps the LLM understand component interfaces even when `defaults` use live data
</Note>

<Note title="Scope Access" type="warning">
Functions and components defined in `callFunc` and `callComponent` have access to variables in their closure. In this example, `tasks`, `setShowForm`, `createTaskFromDraft`, and `updateTaskWithDraft` are all accessible inside the config functions. This is powerful but requires careful management of dependencies.
</Note>

## Next Steps

1. **Set up the proxy server**: See [Backend Proxy: Clone, Run, Connect](/docs/backend-proxy)
2. **Add functions**: Learn how to register functions in [Functions](/docs/functions)
3. **Register components**: Enable generative UI with [Components Registry](/docs/components)
4. **Customize styling**: See [ModalChat Styling](/docs/styling)

